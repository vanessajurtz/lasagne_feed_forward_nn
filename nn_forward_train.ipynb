{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "\n",
    "import data_io_func\n",
    "\n",
    "# set a random numberinitialization seed to make code reproducible:\n",
    "lasagne.random.set_rng(np.random.RandomState(seed=1)) # for lasagne\n",
    "np.random.seed(seed=1) # for shuffling training examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to load some data. Here we'll use MHC class 1 binding data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2471, 9, 21)\n",
      "(618, 9, 21)\n"
     ]
    }
   ],
   "source": [
    "MAX_PEP_SEQ_LEN=9\n",
    "\n",
    "# read in peptide sequences and targets:\n",
    "X_train,y_train = data_io_func.read_pep(\"data/f000\",MAX_PEP_SEQ_LEN)\n",
    "X_val,y_val= data_io_func.read_pep(\"data/c000\",MAX_PEP_SEQ_LEN)\n",
    "\n",
    "# encode data using BLOSUM50:\n",
    "X_train= data_io_func.encode_pep(X_train,MAX_PEP_SEQ_LEN)\n",
    "y_train=np.array(y_train)\n",
    "X_val= data_io_func.encode_pep(X_val,MAX_PEP_SEQ_LEN)\n",
    "y_val=np.array(y_val)\n",
    "\n",
    "# data dimensions now:\n",
    "# (N_SEQS, SEQ_LENGTH, N_FEATURES)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_NN(max_pep_seq_len, n_features, n_hid):\n",
    "\n",
    "    # input layer:\n",
    "    l_in= lasagne.layers.InputLayer((None,max_pep_seq_len,n_features))\n",
    "\n",
    "    # add hidden layer:\n",
    "    l_hid = lasagne.layers.DenseLayer(\n",
    "            l_in,\n",
    "            num_units=n_hid,\n",
    "            nonlinearity=lasagne.nonlinearities.sigmoid,\n",
    "            W=lasagne.init.Normal())\n",
    "\n",
    "    # output layer:\n",
    "    l_out = lasagne.layers.DenseLayer(\n",
    "            l_hid,\n",
    "            num_units=1,\n",
    "            nonlinearity=lasagne.nonlinearities.sigmoid,\n",
    "            W=lasagne.init.Normal())\n",
    "    return l_out,l_in\n",
    "\n",
    "# build a network with 10 hidden neurons:\n",
    "network,inp = build_NN(max_pep_seq_len=9, n_features=21, n_hid=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to define and compile training and validation functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sym_target = T.vector('targets',dtype='float32')\n",
    "sym_l_rate=T.scalar()\n",
    "\n",
    "# TRAINING FUNCTION -----------------------------------------------------------\n",
    "\n",
    "prediction = lasagne.layers.get_output(network)\n",
    "loss = lasagne.objectives.squared_error(prediction.flatten(), sym_target)\n",
    "loss = loss.mean()\n",
    "params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "updates = lasagne.updates.sgd(loss, params, learning_rate=sym_l_rate)\n",
    "\n",
    "# training function:\n",
    "train_fn = theano.function([inp.input_var, sym_target, sym_l_rate], loss, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "# VALIDATION FUNCTION ----------------------------------------------------------\n",
    "\n",
    "val_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "val_loss = lasagne.objectives.squared_error(val_prediction.flatten(),sym_target)\n",
    "val_loss = val_loss.mean()\n",
    "\n",
    "# validation function:\n",
    "val_fn = theano.function([inp.input_var, sym_target], val_loss, allow_input_downcast=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Start training loop...\n",
      "Epoch 1\ttraining error: 0.0507\ttime: 0.005 s\n",
      "Epoch 2\ttraining error: 0.0508\ttime: 0.004 s\n",
      "Epoch 3\ttraining error: 0.0504\ttime: 0.004 s\n",
      "Epoch 4\ttraining error: 0.0504\ttime: 0.004 s\n",
      "Epoch 5\ttraining error: 0.0505\ttime: 0.004 s\n",
      "Epoch 6\ttraining error: 0.0498\ttime: 0.004 s\n",
      "Epoch 7\ttraining error: 0.05\ttime: 0.004 s\n",
      "Epoch 8\ttraining error: 0.0499\ttime: 0.004 s\n",
      "Epoch 9\ttraining error: 0.0497\ttime: 0.004 s\n",
      "Epoch 10\ttraining error: 0.05\tvalidation error: 0.0517\ttime: 0.006 s\n",
      "Epoch 11\ttraining error: 0.0493\ttime: 0.004 s\n",
      "Epoch 12\ttraining error: 0.0493\ttime: 0.004 s\n",
      "Epoch 13\ttraining error: 0.0494\ttime: 0.004 s\n",
      "Epoch 14\ttraining error: 0.0491\ttime: 0.007 s\n",
      "Epoch 15\ttraining error: 0.0492\ttime: 0.006 s\n",
      "Epoch 16\ttraining error: 0.049\ttime: 0.005 s\n",
      "Epoch 17\ttraining error: 0.0492\ttime: 0.004 s\n",
      "Epoch 18\ttraining error: 0.049\ttime: 0.004 s\n",
      "Epoch 19\ttraining error: 0.0491\ttime: 0.004 s\n",
      "Epoch 20\ttraining error: 0.0485\tvalidation error: 0.0512\ttime: 0.006 s\n",
      "Epoch 21\ttraining error: 0.0486\ttime: 0.005 s\n",
      "Epoch 22\ttraining error: 0.0488\ttime: 0.005 s\n",
      "Epoch 23\ttraining error: 0.0485\ttime: 0.004 s\n",
      "Epoch 24\ttraining error: 0.0488\ttime: 0.005 s\n",
      "Epoch 25\ttraining error: 0.0484\ttime: 0.005 s\n",
      "Epoch 26\ttraining error: 0.0483\ttime: 0.005 s\n",
      "Epoch 27\ttraining error: 0.048\ttime: 0.005 s\n",
      "Epoch 28\ttraining error: 0.0476\ttime: 0.004 s\n",
      "Epoch 29\ttraining error: 0.0481\ttime: 0.004 s\n",
      "Epoch 30\ttraining error: 0.0478\tvalidation error: 0.0497\ttime: 0.006 s\n",
      "Epoch 31\ttraining error: 0.0473\ttime: 0.004 s\n",
      "Epoch 32\ttraining error: 0.0475\ttime: 0.004 s\n",
      "Epoch 33\ttraining error: 0.0475\ttime: 0.004 s\n",
      "Epoch 34\ttraining error: 0.0475\ttime: 0.004 s\n",
      "Epoch 35\ttraining error: 0.0472\ttime: 0.003 s\n",
      "Epoch 36\ttraining error: 0.0473\ttime: 0.004 s\n",
      "Epoch 37\ttraining error: 0.0472\ttime: 0.004 s\n",
      "Epoch 38\ttraining error: 0.0469\ttime: 0.004 s\n",
      "Epoch 39\ttraining error: 0.0472\ttime: 0.004 s\n",
      "Epoch 40\ttraining error: 0.0464\tvalidation error: 0.0487\ttime: 0.005 s\n",
      "Epoch 41\ttraining error: 0.0468\ttime: 0.004 s\n",
      "Epoch 42\ttraining error: 0.0468\ttime: 0.004 s\n",
      "Epoch 43\ttraining error: 0.0463\ttime: 0.004 s\n",
      "Epoch 44\ttraining error: 0.0467\ttime: 0.004 s\n",
      "Epoch 45\ttraining error: 0.0466\ttime: 0.004 s\n",
      "Epoch 46\ttraining error: 0.0462\ttime: 0.004 s\n",
      "Epoch 47\ttraining error: 0.0458\ttime: 0.004 s\n",
      "Epoch 48\ttraining error: 0.0465\ttime: 0.004 s\n",
      "Epoch 49\ttraining error: 0.0462\ttime: 0.004 s\n",
      "Epoch 50\ttraining error: 0.0465\tvalidation error: 0.0481\ttime: 0.006 s\n",
      "Epoch 51\ttraining error: 0.0462\ttime: 0.004 s\n",
      "Epoch 52\ttraining error: 0.0456\ttime: 0.004 s\n",
      "Epoch 53\ttraining error: 0.0456\ttime: 0.004 s\n",
      "Epoch 54\ttraining error: 0.0459\ttime: 0.004 s\n",
      "Epoch 55\ttraining error: 0.0457\ttime: 0.004 s\n",
      "Epoch 56\ttraining error: 0.0451\ttime: 0.004 s\n",
      "Epoch 57\ttraining error: 0.0454\ttime: 0.004 s\n",
      "Epoch 58\ttraining error: 0.0449\ttime: 0.004 s\n",
      "Epoch 59\ttraining error: 0.0454\ttime: 0.004 s\n",
      "Epoch 60\ttraining error: 0.0453\tvalidation error: 0.047\ttime: 0.006 s\n",
      "Epoch 61\ttraining error: 0.0454\ttime: 0.004 s\n",
      "Epoch 62\ttraining error: 0.0451\ttime: 0.004 s\n",
      "Epoch 63\ttraining error: 0.0447\ttime: 0.004 s\n",
      "Epoch 64\ttraining error: 0.045\ttime: 0.004 s\n",
      "Epoch 65\ttraining error: 0.0447\ttime: 0.004 s\n",
      "Epoch 66\ttraining error: 0.0444\ttime: 0.004 s\n",
      "Epoch 67\ttraining error: 0.0439\ttime: 0.004 s\n",
      "Epoch 68\ttraining error: 0.0446\ttime: 0.004 s\n",
      "Epoch 69\ttraining error: 0.0441\ttime: 0.004 s\n",
      "Epoch 70\ttraining error: 0.0447\tvalidation error: 0.0455\ttime: 0.005 s\n",
      "Epoch 71\ttraining error: 0.0442\ttime: 0.004 s\n",
      "Epoch 72\ttraining error: 0.0441\ttime: 0.004 s\n",
      "Epoch 73\ttraining error: 0.0439\ttime: 0.004 s\n",
      "Epoch 74\ttraining error: 0.0439\ttime: 0.004 s\n",
      "Epoch 75\ttraining error: 0.0443\ttime: 0.004 s\n",
      "Epoch 76\ttraining error: 0.0444\ttime: 0.004 s\n",
      "Epoch 77\ttraining error: 0.0438\ttime: 0.004 s\n",
      "Epoch 78\ttraining error: 0.0437\ttime: 0.004 s\n",
      "Epoch 79\ttraining error: 0.0441\ttime: 0.004 s\n",
      "Epoch 80\ttraining error: 0.0435\tvalidation error: 0.0446\ttime: 0.006 s\n",
      "Epoch 81\ttraining error: 0.0439\ttime: 0.004 s\n",
      "Epoch 82\ttraining error: 0.0434\ttime: 0.004 s\n",
      "Epoch 83\ttraining error: 0.0434\ttime: 0.005 s\n",
      "Epoch 84\ttraining error: 0.0439\ttime: 0.004 s\n",
      "Epoch 85\ttraining error: 0.0433\ttime: 0.004 s\n",
      "Epoch 86\ttraining error: 0.043\ttime: 0.004 s\n",
      "Epoch 87\ttraining error: 0.0434\ttime: 0.004 s\n",
      "Epoch 88\ttraining error: 0.0434\ttime: 0.004 s\n",
      "Epoch 89\ttraining error: 0.0432\ttime: 0.004 s\n",
      "Epoch 90\ttraining error: 0.0431\tvalidation error: 0.0446\ttime: 0.006 s\n",
      "Epoch 91\ttraining error: 0.0426\ttime: 0.004 s\n",
      "Epoch 92\ttraining error: 0.0433\ttime: 0.004 s\n",
      "Epoch 93\ttraining error: 0.0429\ttime: 0.004 s\n",
      "Epoch 94\ttraining error: 0.0422\ttime: 0.004 s\n",
      "Epoch 95\ttraining error: 0.0428\ttime: 0.004 s\n",
      "Epoch 96\ttraining error: 0.0428\ttime: 0.003 s\n",
      "Epoch 97\ttraining error: 0.0426\ttime: 0.003 s\n",
      "Epoch 98\ttraining error: 0.0424\ttime: 0.003 s\n",
      "Epoch 99\ttraining error: 0.0422\ttime: 0.003 s\n",
      "Epoch 100\ttraining error: 0.0422\tvalidation error: 0.0451\ttime: 0.005 s\n",
      "Epoch 101\ttraining error: 0.0418\ttime: 0.004 s\n",
      "Epoch 102\ttraining error: 0.042\ttime: 0.004 s\n",
      "Epoch 103\ttraining error: 0.0424\ttime: 0.004 s\n",
      "Epoch 104\ttraining error: 0.0417\ttime: 0.004 s\n",
      "Epoch 105\ttraining error: 0.0422\ttime: 0.004 s\n",
      "Epoch 106\ttraining error: 0.0419\ttime: 0.004 s\n",
      "Epoch 107\ttraining error: 0.0418\ttime: 0.003 s\n",
      "Epoch 108\ttraining error: 0.0421\ttime: 0.003 s\n",
      "Epoch 109\ttraining error: 0.0419\ttime: 0.004 s\n",
      "Epoch 110\ttraining error: 0.0418\tvalidation error: 0.0444\ttime: 0.005 s\n",
      "Epoch 111\ttraining error: 0.0417\ttime: 0.004 s\n",
      "Epoch 112\ttraining error: 0.0417\ttime: 0.004 s\n",
      "Epoch 113\ttraining error: 0.0419\ttime: 0.004 s\n",
      "Epoch 114\ttraining error: 0.0417\ttime: 0.004 s\n",
      "Epoch 115\ttraining error: 0.0414\ttime: 0.004 s\n",
      "Epoch 116\ttraining error: 0.0413\ttime: 0.004 s\n",
      "Epoch 117\ttraining error: 0.0414\ttime: 0.004 s\n",
      "Epoch 118\ttraining error: 0.0413\ttime: 0.004 s\n",
      "Epoch 119\ttraining error: 0.0409\ttime: 0.004 s\n",
      "Epoch 120\ttraining error: 0.0407\tvalidation error: 0.0427\ttime: 0.005 s\n",
      "Epoch 121\ttraining error: 0.041\ttime: 0.004 s\n",
      "Epoch 122\ttraining error: 0.0411\ttime: 0.004 s\n",
      "Epoch 123\ttraining error: 0.0406\ttime: 0.004 s\n",
      "Epoch 124\ttraining error: 0.0407\ttime: 0.004 s\n",
      "Epoch 125\ttraining error: 0.041\ttime: 0.004 s\n",
      "Epoch 126\ttraining error: 0.0406\ttime: 0.004 s\n",
      "Epoch 127\ttraining error: 0.0408\ttime: 0.004 s\n",
      "Epoch 128\ttraining error: 0.0408\ttime: 0.004 s\n",
      "Epoch 129\ttraining error: 0.0408\ttime: 0.004 s\n",
      "Epoch 130\ttraining error: 0.0405\tvalidation error: 0.0423\ttime: 0.006 s\n",
      "Epoch 131\ttraining error: 0.0402\ttime: 0.004 s\n",
      "Epoch 132\ttraining error: 0.0405\ttime: 0.004 s\n",
      "Epoch 133\ttraining error: 0.0405\ttime: 0.004 s\n",
      "Epoch 134\ttraining error: 0.0405\ttime: 0.004 s\n",
      "Epoch 135\ttraining error: 0.0403\ttime: 0.004 s\n",
      "Epoch 136\ttraining error: 0.0403\ttime: 0.004 s\n",
      "Epoch 137\ttraining error: 0.0397\ttime: 0.004 s\n",
      "Epoch 138\ttraining error: 0.04\ttime: 0.004 s\n",
      "Epoch 139\ttraining error: 0.0399\ttime: 0.004 s\n",
      "Epoch 140\ttraining error: 0.0403\tvalidation error: 0.0426\ttime: 0.005 s\n",
      "Epoch 141\ttraining error: 0.04\ttime: 0.004 s\n",
      "Epoch 142\ttraining error: 0.0398\ttime: 0.004 s\n",
      "Epoch 143\ttraining error: 0.0397\ttime: 0.004 s\n",
      "Epoch 144\ttraining error: 0.0395\ttime: 0.004 s\n",
      "Epoch 145\ttraining error: 0.04\ttime: 0.004 s\n",
      "Epoch 146\ttraining error: 0.0397\ttime: 0.004 s\n",
      "Epoch 147\ttraining error: 0.0398\ttime: 0.004 s\n",
      "Epoch 148\ttraining error: 0.0395\ttime: 0.004 s\n",
      "Epoch 149\ttraining error: 0.0392\ttime: 0.004 s\n",
      "Epoch 150\ttraining error: 0.0395\tvalidation error: 0.0417\ttime: 0.006 s\n",
      "Epoch 151\ttraining error: 0.0393\ttime: 0.004 s\n",
      "Epoch 152\ttraining error: 0.0391\ttime: 0.004 s\n",
      "Epoch 153\ttraining error: 0.0392\ttime: 0.004 s\n",
      "Epoch 154\ttraining error: 0.0393\ttime: 0.004 s\n",
      "Epoch 155\ttraining error: 0.0396\ttime: 0.004 s\n",
      "Epoch 156\ttraining error: 0.0395\ttime: 0.004 s\n",
      "Epoch 157\ttraining error: 0.0389\ttime: 0.004 s\n",
      "Epoch 158\ttraining error: 0.0392\ttime: 0.004 s\n",
      "Epoch 159\ttraining error: 0.0391\ttime: 0.004 s\n",
      "Epoch 160\ttraining error: 0.0391\tvalidation error: 0.0415\ttime: 0.005 s\n",
      "Epoch 161\ttraining error: 0.0389\ttime: 0.004 s\n",
      "Epoch 162\ttraining error: 0.0386\ttime: 0.004 s\n",
      "Epoch 163\ttraining error: 0.0387\ttime: 0.004 s\n",
      "Epoch 164\ttraining error: 0.0383\ttime: 0.004 s\n",
      "Epoch 165\ttraining error: 0.0391\ttime: 0.004 s\n",
      "Epoch 166\ttraining error: 0.0386\ttime: 0.004 s\n",
      "Epoch 167\ttraining error: 0.0386\ttime: 0.004 s\n",
      "Epoch 168\ttraining error: 0.0388\ttime: 0.004 s\n",
      "Epoch 169\ttraining error: 0.0387\ttime: 0.004 s\n",
      "Epoch 170\ttraining error: 0.0385\tvalidation error: 0.0405\ttime: 0.005 s\n",
      "Epoch 171\ttraining error: 0.0382\ttime: 0.004 s\n",
      "Epoch 172\ttraining error: 0.0388\ttime: 0.004 s\n",
      "Epoch 173\ttraining error: 0.0387\ttime: 0.004 s\n",
      "Epoch 174\ttraining error: 0.0383\ttime: 0.004 s\n",
      "Epoch 175\ttraining error: 0.0385\ttime: 0.004 s\n",
      "Epoch 176\ttraining error: 0.0379\ttime: 0.004 s\n",
      "Epoch 177\ttraining error: 0.0384\ttime: 0.004 s\n",
      "Epoch 178\ttraining error: 0.0382\ttime: 0.004 s\n",
      "Epoch 179\ttraining error: 0.0378\ttime: 0.004 s\n",
      "Epoch 180\ttraining error: 0.0381\tvalidation error: 0.0409\ttime: 0.005 s\n",
      "Epoch 181\ttraining error: 0.0383\ttime: 0.004 s\n",
      "Epoch 182\ttraining error: 0.0376\ttime: 0.004 s\n",
      "Epoch 183\ttraining error: 0.0379\ttime: 0.004 s\n",
      "Epoch 184\ttraining error: 0.038\ttime: 0.004 s\n",
      "Epoch 185\ttraining error: 0.0379\ttime: 0.004 s\n",
      "Epoch 186\ttraining error: 0.0378\ttime: 0.004 s\n",
      "Epoch 187\ttraining error: 0.0378\ttime: 0.004 s\n",
      "Epoch 188\ttraining error: 0.0374\ttime: 0.004 s\n",
      "Epoch 189\ttraining error: 0.0376\ttime: 0.004 s\n",
      "Epoch 190\ttraining error: 0.0378\tvalidation error: 0.0401\ttime: 0.006 s\n",
      "Epoch 191\ttraining error: 0.0377\ttime: 0.005 s\n",
      "Epoch 192\ttraining error: 0.0381\ttime: 0.004 s\n",
      "Epoch 193\ttraining error: 0.0377\ttime: 0.004 s\n",
      "Epoch 194\ttraining error: 0.0373\ttime: 0.004 s\n",
      "Epoch 195\ttraining error: 0.0374\ttime: 0.004 s\n",
      "Epoch 196\ttraining error: 0.0375\ttime: 0.004 s\n",
      "Epoch 197\ttraining error: 0.0373\ttime: 0.004 s\n",
      "Epoch 198\ttraining error: 0.0371\ttime: 0.004 s\n",
      "Epoch 199\ttraining error: 0.0373\ttime: 0.004 s\n",
      "# Best epoch: 190\ttrain error: 0.0378\tvalidation error: 0.0401\n",
      "# Time for training: 0.014 min\n",
      "# Done!\n"
     ]
    }
   ],
   "source": [
    "def iterate_minibatches(pep, targets, batchsize):\n",
    "    assert pep.shape[0] == targets.shape[0]\n",
    "    # shuffle:\n",
    "    indices = np.arange(len(pep))\n",
    "    np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(pep) - batchsize + 1, batchsize):\n",
    "        excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        yield pep[excerpt],targets[excerpt]\n",
    "\n",
    "\n",
    "\n",
    "# TRAINING LOOP ----------------------------------------------------------------\n",
    "\n",
    "EPOCHS=range(1,200)\n",
    "LEARNING_RATE=0.01\n",
    "\n",
    "print(\"# Start training loop...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "b_epoch=0\n",
    "b_train_err=99\n",
    "b_val_err=99\n",
    "\n",
    "for e in EPOCHS:\n",
    "\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "    val_err = 0\n",
    "    val_batches = 0\n",
    "    e_start_time = time.time()\n",
    "\n",
    "    # shuffle training examples and iterate through minbatches:\n",
    "    for batch in iterate_minibatches(X_train, y_train, 200):\n",
    "        Xinp, target = batch\n",
    "        train_err += train_fn(Xinp, target, LEARNING_RATE)\n",
    "        train_batches += 1\n",
    "\n",
    "    if e%10 == 0:\n",
    "        # predict validation set:\n",
    "        for batch in iterate_minibatches(X_val, y_val, 200):\n",
    "            Xinp, target = batch\n",
    "            val_err += val_fn(Xinp, target)\n",
    "            val_batches += 1\n",
    "\n",
    "        \n",
    "        # save only best model:\n",
    "        if (val_err/val_batches) < b_val_err:\n",
    "            np.savez('params.npz', lasagne.layers.get_all_param_values(network))\n",
    "            b_val_err = val_err/val_batches\n",
    "            b_train_err = train_err/train_batches\n",
    "            b_epoch = e\n",
    "        # print performance:\n",
    "        print(\"Epoch \" + str(e) +\n",
    "        \"\\ttraining error: \" + str(round(train_err/train_batches, 4)) +\n",
    "        \"\\tvalidation error: \" + str(round(val_err/val_batches, 4)) +\n",
    "        \"\\ttime: \" + str(round(time.time()-e_start_time, 3)) + \" s\")\n",
    "\n",
    "    else:\n",
    "        # print performance:\n",
    "        print(\"Epoch \" + str(e) +\n",
    "        \"\\ttraining error: \" + str(round(train_err/train_batches, 4)) +\n",
    "        \"\\ttime: \" + str(round(time.time()-e_start_time, 3)) + \" s\")\n",
    "\n",
    "# print best performance:\n",
    "print(\"# Best epoch: \" + str(b_epoch) +\n",
    "        \"\\ttrain error: \" + str(round(b_train_err, 4)) +\n",
    "        \"\\tvalidation error: \" + str(round(b_val_err, 4) ))\n",
    "# report total time used for training:\n",
    "print(\"# Time for training: \" + str(round((time.time()-start_time)/60, 3)) + \" min\" )\n",
    "print(\"# Done!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
