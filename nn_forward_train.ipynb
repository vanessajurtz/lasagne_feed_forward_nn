{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "\n",
    "import data_io_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to load some data. Here we'll use MHC class 1 binding data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2471, 9, 21)\n",
      "(618, 9, 21)\n"
     ]
    }
   ],
   "source": [
    "MAX_PEP_SEQ_LEN=9\n",
    "\n",
    "# read in peptide sequences and targets:\n",
    "X_train,y_train = data_io_func.read_pep(\"data/f000\",MAX_PEP_SEQ_LEN)\n",
    "X_val,y_val= data_io_func.read_pep(\"data/c000\",MAX_PEP_SEQ_LEN)\n",
    "\n",
    "# encode data using BLOSUM50:\n",
    "X_train= data_io_func.encode_pep(X_train,MAX_PEP_SEQ_LEN)\n",
    "y_train=np.array(y_train)\n",
    "X_val= data_io_func.encode_pep(X_val,MAX_PEP_SEQ_LEN)\n",
    "y_val=np.array(y_val)\n",
    "\n",
    "# data dimensions now:\n",
    "# (N_SEQS, SEQ_LENGTH, N_FEATURES)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_NN(max_pep_seq_len, n_features, n_hid):\n",
    "\n",
    "    # input layer:\n",
    "    l_in= lasagne.layers.InputLayer((None,max_pep_seq_len,n_features))\n",
    "\n",
    "    # add hidden layer:\n",
    "    l_hid = lasagne.layers.DenseLayer(\n",
    "            l_in,\n",
    "            num_units=n_hid,\n",
    "            nonlinearity=lasagne.nonlinearities.sigmoid,\n",
    "            W=lasagne.init.Normal())\n",
    "\n",
    "    # output layer:\n",
    "    l_out = lasagne.layers.DenseLayer(\n",
    "            l_hid,\n",
    "            num_units=1,\n",
    "            nonlinearity=lasagne.nonlinearities.sigmoid,\n",
    "            W=lasagne.init.Normal())\n",
    "    return l_out,l_in\n",
    "\n",
    "# build a network with 10 hidden neurons:\n",
    "network,inp = build_NN(max_pep_seq_len=9, n_features=21, n_hid=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to define and compile training and validation functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sym_target = T.vector('targets',dtype='float32')\n",
    "sym_l_rate=T.scalar()\n",
    "\n",
    "# TRAINING FUNCTION -----------------------------------------------------------\n",
    "\n",
    "prediction = lasagne.layers.get_output(network)\n",
    "loss = lasagne.objectives.squared_error(prediction.flatten(), sym_target)\n",
    "loss = loss.mean()\n",
    "params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "updates = lasagne.updates.sgd(loss, params, learning_rate=sym_l_rate)\n",
    "\n",
    "# training function:\n",
    "train_fn = theano.function([inp.input_var, sym_target, sym_l_rate], loss, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "# VALIDATION FUNCTION ----------------------------------------------------------\n",
    "\n",
    "val_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "val_loss = lasagne.objectives.squared_error(val_prediction.flatten(),sym_target)\n",
    "val_loss = val_loss.mean()\n",
    "\n",
    "# validation function:\n",
    "val_fn = theano.function([inp.input_var, sym_target], val_loss, allow_input_downcast=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Start training loop...\n",
      "Epoch 1\ttraining error: 0.1087\ttime: 0.006 s\n",
      "Epoch 2\ttraining error: 0.0981\ttime: 0.004 s\n",
      "Epoch 3\ttraining error: 0.0941\ttime: 0.004 s\n",
      "Epoch 4\ttraining error: 0.0905\ttime: 0.004 s\n",
      "Epoch 5\ttraining error: 0.0871\ttime: 0.004 s\n",
      "Epoch 6\ttraining error: 0.084\ttime: 0.005 s\n",
      "Epoch 7\ttraining error: 0.0809\ttime: 0.004 s\n",
      "Epoch 8\ttraining error: 0.0767\ttime: 0.004 s\n",
      "Epoch 9\ttraining error: 0.0737\ttime: 0.004 s\n",
      "Epoch 10\ttraining error: 0.071\tvalidation error: 0.0705\ttime: 0.006 s\n",
      "Epoch 11\ttraining error: 0.0676\ttime: 0.004 s\n",
      "Epoch 12\ttraining error: 0.0653\ttime: 0.004 s\n",
      "Epoch 13\ttraining error: 0.0637\ttime: 0.005 s\n",
      "Epoch 14\ttraining error: 0.0614\ttime: 0.005 s\n",
      "Epoch 15\ttraining error: 0.0595\ttime: 0.005 s\n",
      "Epoch 16\ttraining error: 0.0576\ttime: 0.004 s\n",
      "Epoch 17\ttraining error: 0.0562\ttime: 0.004 s\n",
      "Epoch 18\ttraining error: 0.0549\ttime: 0.004 s\n",
      "Epoch 19\ttraining error: 0.0533\ttime: 0.004 s\n",
      "Epoch 20\ttraining error: 0.0522\tvalidation error: 0.0521\ttime: 0.005 s\n",
      "Epoch 21\ttraining error: 0.0506\ttime: 0.004 s\n",
      "Epoch 22\ttraining error: 0.0501\ttime: 0.004 s\n",
      "Epoch 23\ttraining error: 0.0489\ttime: 0.004 s\n",
      "Epoch 24\ttraining error: 0.0478\ttime: 0.004 s\n",
      "Epoch 25\ttraining error: 0.0471\ttime: 0.005 s\n",
      "Epoch 26\ttraining error: 0.046\ttime: 0.004 s\n",
      "Epoch 27\ttraining error: 0.0455\ttime: 0.004 s\n",
      "Epoch 28\ttraining error: 0.0447\ttime: 0.004 s\n",
      "Epoch 29\ttraining error: 0.044\ttime: 0.004 s\n",
      "Epoch 30\ttraining error: 0.0432\tvalidation error: 0.0451\ttime: 0.006 s\n",
      "Epoch 31\ttraining error: 0.0424\ttime: 0.004 s\n",
      "Epoch 32\ttraining error: 0.0418\ttime: 0.004 s\n",
      "Epoch 33\ttraining error: 0.0416\ttime: 0.005 s\n",
      "Epoch 34\ttraining error: 0.0407\ttime: 0.004 s\n",
      "Epoch 35\ttraining error: 0.0401\ttime: 0.004 s\n",
      "Epoch 36\ttraining error: 0.0398\ttime: 0.004 s\n",
      "Epoch 37\ttraining error: 0.0389\ttime: 0.004 s\n",
      "Epoch 38\ttraining error: 0.0388\ttime: 0.004 s\n",
      "Epoch 39\ttraining error: 0.038\ttime: 0.004 s\n",
      "Epoch 40\ttraining error: 0.0377\tvalidation error: 0.0406\ttime: 0.005 s\n",
      "Epoch 41\ttraining error: 0.037\ttime: 0.004 s\n",
      "Epoch 42\ttraining error: 0.0368\ttime: 0.004 s\n",
      "Epoch 43\ttraining error: 0.0367\ttime: 0.004 s\n",
      "Epoch 44\ttraining error: 0.036\ttime: 0.004 s\n",
      "Epoch 45\ttraining error: 0.0356\ttime: 0.004 s\n",
      "Epoch 46\ttraining error: 0.0354\ttime: 0.004 s\n",
      "Epoch 47\ttraining error: 0.0353\ttime: 0.003 s\n",
      "Epoch 48\ttraining error: 0.0349\ttime: 0.004 s\n",
      "Epoch 49\ttraining error: 0.0341\ttime: 0.004 s\n",
      "Epoch 50\ttraining error: 0.0345\tvalidation error: 0.0367\ttime: 0.005 s\n",
      "Epoch 51\ttraining error: 0.0341\ttime: 0.004 s\n",
      "Epoch 52\ttraining error: 0.0338\ttime: 0.004 s\n",
      "Epoch 53\ttraining error: 0.0334\ttime: 0.004 s\n",
      "Epoch 54\ttraining error: 0.033\ttime: 0.004 s\n",
      "Epoch 55\ttraining error: 0.0329\ttime: 0.004 s\n",
      "Epoch 56\ttraining error: 0.0323\ttime: 0.004 s\n",
      "Epoch 57\ttraining error: 0.0322\ttime: 0.004 s\n",
      "Epoch 58\ttraining error: 0.0319\ttime: 0.004 s\n",
      "Epoch 59\ttraining error: 0.0323\ttime: 0.004 s\n",
      "Epoch 60\ttraining error: 0.0319\tvalidation error: 0.0348\ttime: 0.006 s\n",
      "Epoch 61\ttraining error: 0.0318\ttime: 0.004 s\n",
      "Epoch 62\ttraining error: 0.0313\ttime: 0.004 s\n",
      "Epoch 63\ttraining error: 0.0312\ttime: 0.004 s\n",
      "Epoch 64\ttraining error: 0.0307\ttime: 0.004 s\n",
      "Epoch 65\ttraining error: 0.0307\ttime: 0.004 s\n",
      "Epoch 66\ttraining error: 0.0308\ttime: 0.004 s\n",
      "Epoch 67\ttraining error: 0.0303\ttime: 0.004 s\n",
      "Epoch 68\ttraining error: 0.0302\ttime: 0.004 s\n",
      "Epoch 69\ttraining error: 0.0302\ttime: 0.004 s\n",
      "Epoch 70\ttraining error: 0.0299\tvalidation error: 0.0337\ttime: 0.006 s\n",
      "Epoch 71\ttraining error: 0.0298\ttime: 0.004 s\n",
      "Epoch 72\ttraining error: 0.0296\ttime: 0.004 s\n",
      "Epoch 73\ttraining error: 0.0293\ttime: 0.004 s\n",
      "Epoch 74\ttraining error: 0.0295\ttime: 0.004 s\n",
      "Epoch 75\ttraining error: 0.0291\ttime: 0.004 s\n",
      "Epoch 76\ttraining error: 0.0289\ttime: 0.004 s\n",
      "Epoch 77\ttraining error: 0.0285\ttime: 0.004 s\n",
      "Epoch 78\ttraining error: 0.0288\ttime: 0.004 s\n",
      "Epoch 79\ttraining error: 0.0282\ttime: 0.004 s\n",
      "Epoch 80\ttraining error: 0.0284\tvalidation error: 0.0315\ttime: 0.005 s\n",
      "Epoch 81\ttraining error: 0.0284\ttime: 0.004 s\n",
      "Epoch 82\ttraining error: 0.0282\ttime: 0.004 s\n",
      "Epoch 83\ttraining error: 0.0279\ttime: 0.004 s\n",
      "Epoch 84\ttraining error: 0.0277\ttime: 0.004 s\n",
      "Epoch 85\ttraining error: 0.0279\ttime: 0.004 s\n",
      "Epoch 86\ttraining error: 0.0275\ttime: 0.004 s\n",
      "Epoch 87\ttraining error: 0.0275\ttime: 0.003 s\n",
      "Epoch 88\ttraining error: 0.0275\ttime: 0.004 s\n",
      "Epoch 89\ttraining error: 0.0272\ttime: 0.004 s\n",
      "Epoch 90\ttraining error: 0.0272\tvalidation error: 0.0302\ttime: 0.006 s\n",
      "Epoch 91\ttraining error: 0.0272\ttime: 0.004 s\n",
      "Epoch 92\ttraining error: 0.0271\ttime: 0.004 s\n",
      "Epoch 93\ttraining error: 0.0268\ttime: 0.004 s\n",
      "Epoch 94\ttraining error: 0.0265\ttime: 0.004 s\n",
      "Epoch 95\ttraining error: 0.0267\ttime: 0.004 s\n",
      "Epoch 96\ttraining error: 0.0266\ttime: 0.004 s\n",
      "Epoch 97\ttraining error: 0.0264\ttime: 0.004 s\n",
      "Epoch 98\ttraining error: 0.0264\ttime: 0.004 s\n",
      "Epoch 99\ttraining error: 0.0267\ttime: 0.003 s\n",
      "Epoch 100\ttraining error: 0.0263\tvalidation error: 0.0301\ttime: 0.005 s\n",
      "Epoch 101\ttraining error: 0.0261\ttime: 0.004 s\n",
      "Epoch 102\ttraining error: 0.0262\ttime: 0.004 s\n",
      "Epoch 103\ttraining error: 0.026\ttime: 0.005 s\n",
      "Epoch 104\ttraining error: 0.0262\ttime: 0.004 s\n",
      "Epoch 105\ttraining error: 0.0258\ttime: 0.004 s\n",
      "Epoch 106\ttraining error: 0.026\ttime: 0.004 s\n",
      "Epoch 107\ttraining error: 0.0256\ttime: 0.004 s\n",
      "Epoch 108\ttraining error: 0.0257\ttime: 0.004 s\n",
      "Epoch 109\ttraining error: 0.0256\ttime: 0.004 s\n",
      "Epoch 110\ttraining error: 0.0254\tvalidation error: 0.029\ttime: 0.005 s\n",
      "Epoch 111\ttraining error: 0.0254\ttime: 0.004 s\n",
      "Epoch 112\ttraining error: 0.0253\ttime: 0.004 s\n",
      "Epoch 113\ttraining error: 0.0251\ttime: 0.004 s\n",
      "Epoch 114\ttraining error: 0.0251\ttime: 0.004 s\n",
      "Epoch 115\ttraining error: 0.0253\ttime: 0.004 s\n",
      "Epoch 116\ttraining error: 0.025\ttime: 0.004 s\n",
      "Epoch 117\ttraining error: 0.0248\ttime: 0.004 s\n",
      "Epoch 118\ttraining error: 0.025\ttime: 0.004 s\n",
      "Epoch 119\ttraining error: 0.025\ttime: 0.004 s\n",
      "Epoch 120\ttraining error: 0.0249\tvalidation error: 0.0289\ttime: 0.005 s\n",
      "Epoch 121\ttraining error: 0.0245\ttime: 0.004 s\n",
      "Epoch 122\ttraining error: 0.0245\ttime: 0.004 s\n",
      "Epoch 123\ttraining error: 0.0246\ttime: 0.004 s\n",
      "Epoch 124\ttraining error: 0.0247\ttime: 0.004 s\n",
      "Epoch 125\ttraining error: 0.0243\ttime: 0.004 s\n",
      "Epoch 126\ttraining error: 0.0245\ttime: 0.003 s\n",
      "Epoch 127\ttraining error: 0.024\ttime: 0.004 s\n",
      "Epoch 128\ttraining error: 0.0241\ttime: 0.004 s\n",
      "Epoch 129\ttraining error: 0.0242\ttime: 0.004 s\n",
      "Epoch 130\ttraining error: 0.0238\tvalidation error: 0.0287\ttime: 0.006 s\n",
      "Epoch 131\ttraining error: 0.0238\ttime: 0.004 s\n",
      "Epoch 132\ttraining error: 0.0241\ttime: 0.004 s\n",
      "Epoch 133\ttraining error: 0.0238\ttime: 0.004 s\n",
      "Epoch 134\ttraining error: 0.0242\ttime: 0.004 s\n",
      "Epoch 135\ttraining error: 0.0238\ttime: 0.004 s\n",
      "Epoch 136\ttraining error: 0.0239\ttime: 0.004 s\n",
      "Epoch 137\ttraining error: 0.0239\ttime: 0.004 s\n",
      "Epoch 138\ttraining error: 0.0237\ttime: 0.004 s\n",
      "Epoch 139\ttraining error: 0.0237\ttime: 0.004 s\n",
      "Epoch 140\ttraining error: 0.0237\tvalidation error: 0.0276\ttime: 0.005 s\n",
      "Epoch 141\ttraining error: 0.0237\ttime: 0.004 s\n",
      "Epoch 142\ttraining error: 0.0237\ttime: 0.005 s\n",
      "Epoch 143\ttraining error: 0.0235\ttime: 0.004 s\n",
      "Epoch 144\ttraining error: 0.0236\ttime: 0.004 s\n",
      "Epoch 145\ttraining error: 0.0235\ttime: 0.004 s\n",
      "Epoch 146\ttraining error: 0.0233\ttime: 0.004 s\n",
      "Epoch 147\ttraining error: 0.0236\ttime: 0.004 s\n",
      "Epoch 148\ttraining error: 0.0234\ttime: 0.004 s\n",
      "Epoch 149\ttraining error: 0.0234\ttime: 0.004 s\n",
      "Epoch 150\ttraining error: 0.0233\tvalidation error: 0.0269\ttime: 0.005 s\n",
      "Epoch 151\ttraining error: 0.0233\ttime: 0.004 s\n",
      "Epoch 152\ttraining error: 0.0233\ttime: 0.004 s\n",
      "Epoch 153\ttraining error: 0.0228\ttime: 0.004 s\n",
      "Epoch 154\ttraining error: 0.0231\ttime: 0.005 s\n",
      "Epoch 155\ttraining error: 0.0229\ttime: 0.004 s\n",
      "Epoch 156\ttraining error: 0.0227\ttime: 0.004 s\n",
      "Epoch 157\ttraining error: 0.0231\ttime: 0.004 s\n",
      "Epoch 158\ttraining error: 0.0225\ttime: 0.004 s\n",
      "Epoch 159\ttraining error: 0.0227\ttime: 0.004 s\n",
      "Epoch 160\ttraining error: 0.0227\tvalidation error: 0.0268\ttime: 0.006 s\n",
      "Epoch 161\ttraining error: 0.0229\ttime: 0.004 s\n",
      "Epoch 162\ttraining error: 0.0228\ttime: 0.004 s\n",
      "Epoch 163\ttraining error: 0.0225\ttime: 0.004 s\n",
      "Epoch 164\ttraining error: 0.0226\ttime: 0.004 s\n",
      "Epoch 165\ttraining error: 0.0228\ttime: 0.004 s\n",
      "Epoch 166\ttraining error: 0.0225\ttime: 0.004 s\n",
      "Epoch 167\ttraining error: 0.0225\ttime: 0.004 s\n",
      "Epoch 168\ttraining error: 0.0227\ttime: 0.004 s\n",
      "Epoch 169\ttraining error: 0.0224\ttime: 0.004 s\n",
      "Epoch 170\ttraining error: 0.0225\tvalidation error: 0.027\ttime: 0.005 s\n",
      "Epoch 171\ttraining error: 0.0222\ttime: 0.004 s\n",
      "Epoch 172\ttraining error: 0.0224\ttime: 0.004 s\n",
      "Epoch 173\ttraining error: 0.0225\ttime: 0.004 s\n",
      "Epoch 174\ttraining error: 0.0221\ttime: 0.003 s\n",
      "Epoch 175\ttraining error: 0.0224\ttime: 0.004 s\n",
      "Epoch 176\ttraining error: 0.0224\ttime: 0.004 s\n",
      "Epoch 177\ttraining error: 0.0221\ttime: 0.004 s\n",
      "Epoch 178\ttraining error: 0.0223\ttime: 0.004 s\n",
      "Epoch 179\ttraining error: 0.022\ttime: 0.004 s\n",
      "Epoch 180\ttraining error: 0.0219\tvalidation error: 0.0265\ttime: 0.005 s\n",
      "Epoch 181\ttraining error: 0.0221\ttime: 0.004 s\n",
      "Epoch 182\ttraining error: 0.0219\ttime: 0.004 s\n",
      "Epoch 183\ttraining error: 0.0219\ttime: 0.004 s\n",
      "Epoch 184\ttraining error: 0.0221\ttime: 0.004 s\n",
      "Epoch 185\ttraining error: 0.022\ttime: 0.004 s\n",
      "Epoch 186\ttraining error: 0.0219\ttime: 0.003 s\n",
      "Epoch 187\ttraining error: 0.0219\ttime: 0.003 s\n",
      "Epoch 188\ttraining error: 0.0216\ttime: 0.003 s\n",
      "Epoch 189\ttraining error: 0.0217\ttime: 0.004 s\n",
      "Epoch 190\ttraining error: 0.0219\tvalidation error: 0.0267\ttime: 0.004 s\n",
      "Epoch 191\ttraining error: 0.022\ttime: 0.004 s\n",
      "Epoch 192\ttraining error: 0.0216\ttime: 0.004 s\n",
      "Epoch 193\ttraining error: 0.0215\ttime: 0.004 s\n",
      "Epoch 194\ttraining error: 0.0213\ttime: 0.003 s\n",
      "Epoch 195\ttraining error: 0.0218\ttime: 0.003 s\n",
      "Epoch 196\ttraining error: 0.0215\ttime: 0.004 s\n",
      "Epoch 197\ttraining error: 0.0214\ttime: 0.004 s\n",
      "Epoch 198\ttraining error: 0.0215\ttime: 0.004 s\n",
      "Epoch 199\ttraining error: 0.0218\ttime: 0.004 s\n",
      "# Best epoch: 180\ttrain error: 0.0219\tvalidation error: 0.0265\n",
      "# Time for training: 0.014 min\n",
      "# Done!\n"
     ]
    }
   ],
   "source": [
    "def iterate_minibatches(pep, targets, batchsize):\n",
    "    assert pep.shape[0] == targets.shape[0]\n",
    "    # shuffle:\n",
    "    indices = np.arange(len(pep))\n",
    "    np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(pep) - batchsize + 1, batchsize):\n",
    "        excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        yield pep[excerpt],targets[excerpt]\n",
    "\n",
    "\n",
    "\n",
    "# TRAINING LOOP ----------------------------------------------------------------\n",
    "\n",
    "EPOCHS=range(1,200)\n",
    "LEARNING_RATE=0.1\n",
    "\n",
    "print(\"# Start training loop...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "b_epoch=0\n",
    "b_train_err=99\n",
    "b_val_err=99\n",
    "\n",
    "for e in EPOCHS:\n",
    "\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "    val_err = 0\n",
    "    val_batches = 0\n",
    "    e_start_time = time.time()\n",
    "\n",
    "    # shuffle training examples and iterate through minbatches:\n",
    "    for batch in iterate_minibatches(X_train, y_train, 200):\n",
    "        Xinp, target = batch\n",
    "        train_err += train_fn(Xinp, target, LEARNING_RATE)\n",
    "        train_batches += 1\n",
    "\n",
    "    if e%10 == 0:\n",
    "        # predict validation set:\n",
    "        for batch in iterate_minibatches(X_val, y_val, 200):\n",
    "            Xinp, target = batch\n",
    "            val_err += val_fn(Xinp, target)\n",
    "            val_batches += 1\n",
    "\n",
    "        \n",
    "        # save only best model:\n",
    "        if (val_err/val_batches) < b_val_err:\n",
    "            np.savez('params.npz', lasagne.layers.get_all_param_values(network))\n",
    "            b_val_err = val_err/val_batches\n",
    "            b_train_err = train_err/train_batches\n",
    "            b_epoch = e\n",
    "        # print performance:\n",
    "        print(\"Epoch \" + str(e) +\n",
    "        \"\\ttraining error: \" + str(round(train_err/train_batches, 4)) +\n",
    "        \"\\tvalidation error: \" + str(round(val_err/val_batches, 4)) +\n",
    "        \"\\ttime: \" + str(round(time.time()-e_start_time, 3)) + \" s\")\n",
    "\n",
    "    else:\n",
    "        # print performance:\n",
    "        print(\"Epoch \" + str(e) +\n",
    "        \"\\ttraining error: \" + str(round(train_err/train_batches, 4)) +\n",
    "        \"\\ttime: \" + str(round(time.time()-e_start_time, 3)) + \" s\")\n",
    "\n",
    "# print best performance:\n",
    "print(\"# Best epoch: \" + str(b_epoch) +\n",
    "        \"\\ttrain error: \" + str(round(b_train_err, 4)) +\n",
    "        \"\\tvalidation error: \" + str(round(b_val_err, 4) ))\n",
    "# report total time used for training:\n",
    "print(\"# Time for training: \" + str(round((time.time()-start_time)/60, 3)) + \" min\" )\n",
    "print(\"# Done!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
